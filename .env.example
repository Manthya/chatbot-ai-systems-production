# Environment Configuration
# Copy this file to .env and fill in your values

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=true
LOG_LEVEL=INFO

# LLM Provider Configuration
# Default provider: ollama (local), openai, anthropic
DEFAULT_LLM_PROVIDER=ollama

# Ollama Configuration (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# OpenAI Configuration (Phase 3)
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_MODEL=gpt-4o-mini

# Anthropic Configuration (Phase 3)
# ANTHROPIC_API_KEY=your-anthropic-api-key
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# Frontend Configuration
FRONTEND_URL=http://localhost:3000
CORS_ORIGINS=["http://localhost:3000","http://localhost:8000"]

# Database Configuration (Phase 2)
# DATABASE_URL=postgresql://user:password@localhost:5432/chatbot

# Redis Configuration (Phase 2)
# REDIS_URL=redis://localhost:6379/0
